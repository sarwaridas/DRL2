{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "!git clone https://github.com/nogibjj/DRL2.git"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DRL2'...\n",
            "remote: Enumerating objects: 136, done.\u001b[K\n",
            "remote: Total 136 (delta 0), reused 0 (delta 0), pack-reused 136\u001b[K\n",
            "Receiving objects: 100% (136/136), 70.34 KiB | 17.59 MiB/s, done.\n",
            "Resolving deltas: 100% (64/64), done.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6OS5Q-WRSu6",
        "outputId": "dc5ba582-a597-4150-94b9-a793e404d34a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "!pip install trfl"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 28.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from trfl) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from trfl) (1.21.6)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from trfl) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from trfl) (1.3.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from trfl) (1.14.1)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63WL4W5fRUrE",
        "outputId": "a1a8b337-d25d-42d1-8b38-938e0cdd4cb8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "%cd /content/drive/MyDrive/AIPI_FinalProject/code"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AIPI_FinalProject/code\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FS6g8xmGR0Lr",
        "outputId": "9d9ae1ba-dcc6-443d-d837-e655dd93532a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "!python3 split_data.py\n",
        "!python3 replay_buffer.py\n",
        "!python3 pop.py"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9.0\n",
            "20.0\n",
            "1.0\n",
            "27.0\n",
            "21.0\n",
            "18.0\n",
            "15.0\n",
            "16.0\n",
            "26.0\n"
          ]
        }
      ],
      "metadata": {
        "id": "4kwGdzz5RXjM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111bed64-f0aa-4a49-c33c-cba67de6099a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "! python /content/drive/MyDrive/AIPI_FinalProject/code/SA2C.py  --model=SASRec #default number of epochs has been set to 5"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AIPI_FinalProject/code/SA2C.py:188: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  self.seq = tf.compat.v1.layers.dropout(self.seq,\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SASRecModules.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SASRecModules.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SASRecModules.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SASRecModules.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SASRecModules.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SASRecModules.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SASRecModules.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SASRecModules.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SA2C.py:216: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,)\n",
            "/content/drive/MyDrive/AIPI_FinalProject/code/SA2C.py:219: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,)\n",
            "2022-12-11 00:08:20.953239: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "the loss in 200th batch is: 10.942031\n",
            "the loss in 400th batch is: 10.683977\n",
            "the loss in 600th batch is: 10.584681\n",
            "the loss in 800th batch is: 10.754261\n",
            "the loss in 1000th batch is: 10.545178\n",
            "the loss in 1200th batch is: 10.494149\n",
            "the loss in 1400th batch is: 10.365561\n",
            "the loss in 1600th batch is: 10.085302\n",
            "the loss in 1800th batch is: 10.349507\n",
            "the loss in 2000th batch is: 10.400964\n",
            "the loss in 2200th batch is: 10.600713\n",
            "the loss in 2400th batch is: 10.105415\n",
            "the loss in 2600th batch is: 9.994789\n",
            "the loss in 2800th batch is: 10.022302\n",
            "the loss in 3000th batch is: 9.959388\n",
            "the loss in 3200th batch is: 10.092787\n",
            "the loss in 3400th batch is: 9.601064\n",
            "the loss in 3600th batch is: 9.747793\n",
            "the loss in 3800th batch is: 9.836881\n",
            "the loss in 4000th batch is: 9.628722\n",
            "the loss in 4200th batch is: 9.724697\n",
            "the loss in 4400th batch is: 9.822890\n",
            "the loss in 4600th batch is: 9.606820\n",
            "the loss in 4800th batch is: 9.362852\n",
            "the loss in 5000th batch is: 9.334516\n",
            "the loss in 5200th batch is: 9.149226\n",
            "the loss in 5400th batch is: 9.318354\n",
            "the loss in 5600th batch is: 9.404636\n",
            "the loss in 5800th batch is: 9.062693\n",
            "the loss in 6000th batch is: 8.749819\n",
            "the loss in 6200th batch is: 9.123200\n",
            "the loss in 6400th batch is: 8.761822\n",
            "the loss in 6600th batch is: 8.714684\n",
            "the loss in 6800th batch is: 9.248535\n",
            "the loss in 7000th batch is: 8.811868\n",
            "the loss in 7200th batch is: 8.493402\n",
            "the loss in 7400th batch is: 8.429915\n",
            "the loss in 7600th batch is: 8.572878\n",
            "the loss in 7800th batch is: 8.221352\n",
            "the loss in 8000th batch is: 8.797457\n",
            "tcmalloc: large alloc 1198252032 bytes == 0xbb916000 @  0x7f6004a601e7 0x7f5fcf2c814e 0x7f5fcf320745 0x7f5fcf320878 0x7f5fcf366597 0x7f5fcf36a7dc 0x7f5fcf3b9a72 0x5aae14 0x5d8416 0x5630f5 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x5d8506 0x7f5fcf30a944 0x5d814d 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x55d743 0x642630 0x6426ae 0x644b78 0x64511c\n",
            "tcmalloc: large alloc 1824587776 bytes == 0xbb916000 @  0x7f6004a601e7 0x7f5fcf2c814e 0x7f5fcf320745 0x7f5fcf320878 0x7f5fcf366597 0x7f5fcf36a7dc 0x7f5fcf3b9a72 0x5aae14 0x5d8416 0x5630f5 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x5d8506 0x7f5fcf30a944 0x5d814d 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x55d743 0x642630 0x6426ae 0x644b78 0x64511c\n",
            "#############################################################\n",
            "total clicks: 117809, total purchase:5807\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 5374.600000\n",
            "clicks hr ndcg @ 3 : 0.143181, 0.121802\n",
            "purchase hr and ndcg @3 : 0.344584, 0.309129\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 6140.400000\n",
            "clicks hr ndcg @ 5 : 0.168255, 0.132122\n",
            "purchase hr and ndcg @5 : 0.374720, 0.321527\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 6826.800000\n",
            "clicks hr ndcg @ 8 : 0.190257, 0.139537\n",
            "purchase hr and ndcg @8 : 0.403651, 0.331278\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.028983, 0.087442\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 8.140539\n",
            "the loss in 8400th batch is: 8.206349\n",
            "the loss in 8600th batch is: 8.247269\n",
            "the loss in 8800th batch is: 8.656878\n",
            "the loss in 9000th batch is: 7.452170\n",
            "the loss in 9200th batch is: 8.023594\n",
            "the loss in 9400th batch is: 8.007112\n",
            "the loss in 9600th batch is: 8.282633\n",
            "the loss in 9800th batch is: 7.846459\n",
            "the loss in 10000th batch is: 7.755440\n",
            "the loss in 10200th batch is: 7.618677\n",
            "the loss in 10400th batch is: 7.846099\n",
            "the loss in 10600th batch is: 7.792509\n",
            "the loss in 10800th batch is: 7.393419\n",
            "the loss in 11000th batch is: 7.833068\n",
            "the loss in 11200th batch is: 7.388800\n",
            "the loss in 11400th batch is: 7.680883\n",
            "the loss in 11600th batch is: 7.768888\n",
            "the loss in 11800th batch is: 7.547065\n",
            "the loss in 12000th batch is: 7.170820\n",
            "the loss in 12200th batch is: 7.922776\n",
            "the loss in 12400th batch is: 7.405731\n",
            "the loss in 12600th batch is: 7.487168\n",
            "the loss in 12800th batch is: 7.261098\n",
            "the loss in 13000th batch is: 7.187732\n",
            "the loss in 13200th batch is: 6.890438\n",
            "the loss in 13400th batch is: 6.967188\n",
            "the loss in 13600th batch is: 7.206138\n",
            "the loss in 13800th batch is: 6.985625\n",
            "the loss in 14000th batch is: 7.142087\n",
            "the loss in 14200th batch is: 7.038754\n",
            "the loss in 14400th batch is: 7.043236\n",
            "the loss in 14600th batch is: 7.116852\n",
            "the loss in 14800th batch is: 6.718358\n",
            "the loss in 15000th batch is: 6.775878\n",
            "the loss in 15200th batch is: 1.187180\n",
            "the loss in 15400th batch is: 1.268669\n",
            "the loss in 15600th batch is: 1.140128\n",
            "the loss in 15800th batch is: 1.083680\n",
            "the loss in 16000th batch is: 1.136955\n",
            "tcmalloc: large alloc 1824587776 bytes == 0xbb916000 @  0x7f6004a601e7 0x7f5fcf2c814e 0x7f5fcf320745 0x7f5fcf320878 0x7f5fcf366597 0x7f5fcf36a7dc 0x7f5fcf3b9a72 0x5aae14 0x5d8416 0x5630f5 0x55cd91 0x5d8941 0x49abe4 0x55cd91 0x5d8941 0x5d8506 0x7f5fcf30a944 0x5d814d 0x5d8d8c 0x55dc1e 0x55cd91 0x5d8941 0x4997c7 0x5d8868 0x4990ca 0x55cd91 0x55d743 0x642630 0x6426ae 0x644b78 0x64511c\n",
            "#############################################################\n",
            "total clicks: 117809, total purchase:5807\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 6705.800000\n",
            "clicks hr ndcg @ 3 : 0.180962, 0.153605\n",
            "purchase hr and ndcg @3 : 0.420527, 0.374481\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 7720.200000\n",
            "clicks hr ndcg @ 5 : 0.214423, 0.167379\n",
            "purchase hr and ndcg @5 : 0.459445, 0.390397\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 8574.600000\n",
            "clicks hr ndcg @ 8 : 0.243004, 0.177011\n",
            "purchase hr and ndcg @8 : 0.490615, 0.400950\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.045259, 0.127165\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 0.995777\n",
            "the loss in 16400th batch is: 0.999502\n",
            "the loss in 16600th batch is: 1.046589\n",
            "the loss in 16800th batch is: 0.954122\n",
            "the loss in 17000th batch is: 0.893029\n",
            "the loss in 17200th batch is: 0.944638\n",
            "the loss in 17400th batch is: 0.993735\n",
            "the loss in 17600th batch is: 0.956095\n",
            "the loss in 17800th batch is: 0.968640\n",
            "the loss in 18000th batch is: 0.966198\n",
            "the loss in 18200th batch is: 0.963317\n",
            "the loss in 18400th batch is: 0.960093\n",
            "the loss in 18600th batch is: 0.890355\n",
            "the loss in 18800th batch is: 0.955334\n",
            "the loss in 19000th batch is: 0.904999\n",
            "the loss in 19200th batch is: 0.960884\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lk5wqaHrWlhz",
        "outputId": "1d1d34bd-e53f-4af0-9d13-581ae49e0f76"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "uVduNFFEWsAb"
      }
    }
  ]
}