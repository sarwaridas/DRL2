{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hhCmeEaVZQo",
        "outputId": "f57d606a-0794-4af9-9259-36b68c34f8b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/AIPI_590/Final Project\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/AIPI_590/Final Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqsMlQYCbmau",
        "outputId": "db3827c3-14f5-401f-9564-bb42f269c8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'DRL1' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nogibjj/DRL2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lozUTBVYfaVx",
        "outputId": "bd12f2a3-81d0-4b39-8919-f4157dfe63ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting trfl\n",
            "  Downloading trfl-1.2.0-py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 4.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from trfl) (1.21.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from trfl) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from trfl) (1.15.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from trfl) (0.1.7)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.8/dist-packages (from trfl) (1.14.1)\n",
            "Installing collected packages: trfl\n",
            "Successfully installed trfl-1.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install trfl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxCJnJVUbx6t",
        "outputId": "495dabeb-5dc0-41c6-cc1c-672d9446d650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "1.0\n",
            "2.0\n",
            "3.0\n",
            "4.0\n",
            "5.0\n",
            "6.0\n",
            "7.0\n",
            "8.0\n"
          ]
        }
      ],
      "source": [
        "!python3 \"DRL1/src/split_data.py\"\n",
        "!python3 \"DRL1/src/replay_buffer.py\"\n",
        "! python DRL1/src/pop.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LvNslwKPdWhx"
      },
      "outputs": [],
      "source": [
        "# timer\n",
        "import time\n",
        "start_t = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeWxT5olfkMM",
        "outputId": "4e9530c2-a0ec-4dd2-9d89-421ea10946d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-01 23:12:07.037194: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "DRL1/src/SA2C.py:188: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  self.seq = tf.compat.v1.layers.dropout(self.seq,\n",
            "/content/drive/MyDrive/AIPI_590/Final Project/DRL1/src/SASRecModules.py:142: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  Q = tf.compat.v1.layers.dense(queries, num_units, activation=None) # (N, T_q, C)\n",
            "/content/drive/MyDrive/AIPI_590/Final Project/DRL1/src/SASRecModules.py:143: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  K = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/drive/MyDrive/AIPI_590/Final Project/DRL1/src/SASRecModules.py:144: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  V = tf.compat.v1.layers.dense(keys, num_units, activation=None) # (N, T_k, C)\n",
            "/content/drive/MyDrive/AIPI_590/Final Project/DRL1/src/SASRecModules.py:184: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "/content/drive/MyDrive/AIPI_590/Final Project/DRL1/src/SASRecModules.py:223: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/drive/MyDrive/AIPI_590/Final Project/DRL1/src/SASRecModules.py:224: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "/content/drive/MyDrive/AIPI_590/Final Project/DRL1/src/SASRecModules.py:228: UserWarning: `tf.layers.conv1d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv1D` instead.\n",
            "  outputs = tf.compat.v1.layers.conv1d(**params)\n",
            "/content/drive/MyDrive/AIPI_590/Final Project/DRL1/src/SASRecModules.py:229: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n",
            "  outputs = tf.compat.v1.layers.dropout(outputs, rate=dropout_rate, training=tf.convert_to_tensor(value=is_training))\n",
            "DRL1/src/SA2C.py:216: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output1 = tf.compat.v1.layers.dense(self.states_hidden, self.item_num,)\n",
            "DRL1/src/SA2C.py:219: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  self.output2= tf.compat.v1.layers.dense(self.states_hidden, self.item_num,)\n",
            "2022-12-01 23:12:21.744973: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2022-12-01 23:12:23.789746: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-12-01 23:12:23.789818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38368 MB memory:  -> device: 0, name: A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n",
            "2022-12-01 23:12:23.876444: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
            "2022-12-01 23:12:27.671747: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
            "2022-12-01 23:12:29.588327: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8101\n",
            "the loss in 200th batch is: 10.729527\n",
            "the loss in 400th batch is: 10.636295\n",
            "the loss in 600th batch is: 10.384671\n",
            "the loss in 800th batch is: 10.141659\n",
            "the loss in 1000th batch is: 10.284557\n",
            "the loss in 1200th batch is: 10.184750\n",
            "the loss in 1400th batch is: 10.159739\n",
            "the loss in 1600th batch is: 10.100454\n",
            "the loss in 1800th batch is: 10.020549\n",
            "the loss in 2000th batch is: 10.000330\n",
            "the loss in 2200th batch is: 9.872331\n",
            "the loss in 2400th batch is: 9.627954\n",
            "the loss in 2600th batch is: 9.739743\n",
            "the loss in 2800th batch is: 9.860582\n",
            "the loss in 3000th batch is: 9.756746\n",
            "the loss in 3200th batch is: 9.917370\n",
            "the loss in 3400th batch is: 9.670624\n",
            "the loss in 3600th batch is: 9.509952\n",
            "the loss in 3800th batch is: 9.502546\n",
            "the loss in 4000th batch is: 9.409125\n",
            "the loss in 4200th batch is: 9.474505\n",
            "the loss in 4400th batch is: 9.419865\n",
            "the loss in 4600th batch is: 9.344101\n",
            "the loss in 4800th batch is: 9.314084\n",
            "the loss in 5000th batch is: 9.080367\n",
            "the loss in 5200th batch is: 9.307650\n",
            "the loss in 5400th batch is: 9.008834\n",
            "the loss in 5600th batch is: 9.076799\n",
            "the loss in 5800th batch is: 9.144466\n",
            "the loss in 6000th batch is: 8.982880\n",
            "the loss in 6200th batch is: 9.063576\n",
            "the loss in 6400th batch is: 8.687842\n",
            "the loss in 6600th batch is: 8.929415\n",
            "the loss in 6800th batch is: 8.891321\n",
            "the loss in 7000th batch is: 8.610415\n",
            "the loss in 7200th batch is: 8.616526\n",
            "the loss in 7400th batch is: 8.499022\n",
            "the loss in 7600th batch is: 8.660977\n",
            "the loss in 7800th batch is: 8.374391\n",
            "the loss in 8000th batch is: 8.469078\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 1106.600000\n",
            "clicks hr ndcg @ 3 : 0.063147, 0.047835\n",
            "purchase hr and ndcg @3 : 0.062456, 0.048429\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 1553.400000\n",
            "clicks hr ndcg @ 5 : 0.089073, 0.058456\n",
            "purchase hr and ndcg @5 : 0.082807, 0.056640\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 2076.600000\n",
            "clicks hr ndcg @ 8 : 0.119182, 0.068588\n",
            "purchase hr and ndcg @8 : 0.109474, 0.065562\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.007973, 0.004842\n",
            "#############################################################\n",
            "the loss in 8200th batch is: 8.464113\n",
            "the loss in 8400th batch is: 8.422100\n",
            "the loss in 8600th batch is: 8.428825\n",
            "the loss in 8800th batch is: 8.349299\n",
            "the loss in 9000th batch is: 8.401672\n",
            "the loss in 9200th batch is: 8.636939\n",
            "the loss in 9400th batch is: 8.374210\n",
            "the loss in 9600th batch is: 8.427277\n",
            "the loss in 9800th batch is: 8.570881\n",
            "the loss in 10000th batch is: 7.639462\n",
            "the loss in 10200th batch is: 8.168514\n",
            "the loss in 10400th batch is: 7.566926\n",
            "the loss in 10600th batch is: 7.793849\n",
            "the loss in 10800th batch is: 7.988675\n",
            "the loss in 11000th batch is: 7.778753\n",
            "the loss in 11200th batch is: 7.948507\n",
            "the loss in 11400th batch is: 8.020798\n",
            "the loss in 11600th batch is: 7.750477\n",
            "the loss in 11800th batch is: 7.552546\n",
            "the loss in 12000th batch is: 7.365456\n",
            "the loss in 12200th batch is: 7.669796\n",
            "the loss in 12400th batch is: 7.379189\n",
            "the loss in 12600th batch is: 7.588253\n",
            "the loss in 12800th batch is: 7.348115\n",
            "the loss in 13000th batch is: 7.504916\n",
            "the loss in 13200th batch is: 7.860880\n",
            "the loss in 13400th batch is: 7.816251\n",
            "the loss in 13600th batch is: 7.572239\n",
            "the loss in 13800th batch is: 6.970972\n",
            "the loss in 14000th batch is: 7.779704\n",
            "the loss in 14200th batch is: 7.521353\n",
            "the loss in 14400th batch is: 7.740028\n",
            "the loss in 14600th batch is: 7.035522\n",
            "the loss in 14800th batch is: 7.438132\n",
            "the loss in 15000th batch is: 7.039962\n",
            "the loss in 15200th batch is: 1.018387\n",
            "the loss in 15400th batch is: 1.089800\n",
            "the loss in 15600th batch is: 0.972242\n",
            "the loss in 15800th batch is: 0.884979\n",
            "the loss in 16000th batch is: 0.900291\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 1724.800000\n",
            "clicks hr ndcg @ 3 : 0.097662, 0.074857\n",
            "purchase hr and ndcg @3 : 0.105965, 0.082564\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 2349.400000\n",
            "clicks hr ndcg @ 5 : 0.133815, 0.089720\n",
            "purchase hr and ndcg @5 : 0.135439, 0.094704\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 3033.800000\n",
            "clicks hr ndcg @ 8 : 0.173182, 0.102977\n",
            "purchase hr and ndcg @8 : 0.170526, 0.106622\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.014514, 0.010010\n",
            "#############################################################\n",
            "the loss in 16200th batch is: 0.907496\n",
            "the loss in 16400th batch is: 0.874602\n",
            "the loss in 16600th batch is: 0.973895\n",
            "the loss in 16800th batch is: 0.963138\n",
            "the loss in 17000th batch is: 0.939520\n",
            "the loss in 17200th batch is: 0.890557\n",
            "the loss in 17400th batch is: 0.921093\n",
            "the loss in 17600th batch is: 0.916208\n",
            "the loss in 17800th batch is: 0.890385\n",
            "the loss in 18000th batch is: 0.906663\n",
            "the loss in 18200th batch is: 0.801270\n",
            "the loss in 18400th batch is: 0.859737\n",
            "the loss in 18600th batch is: 0.824208\n",
            "the loss in 18800th batch is: 0.927633\n",
            "the loss in 19000th batch is: 0.942226\n",
            "the loss in 19200th batch is: 0.935657\n",
            "the loss in 19400th batch is: 0.819915\n",
            "the loss in 19600th batch is: 0.851495\n",
            "the loss in 19800th batch is: 0.805549\n",
            "the loss in 20000th batch is: 0.884611\n",
            "the loss in 20200th batch is: 0.872881\n",
            "the loss in 20400th batch is: 0.913985\n",
            "the loss in 20600th batch is: 0.882565\n",
            "the loss in 20800th batch is: 0.852993\n",
            "the loss in 21000th batch is: 0.847512\n",
            "the loss in 21200th batch is: 0.824361\n",
            "the loss in 21400th batch is: 0.860417\n",
            "the loss in 21600th batch is: 0.854825\n",
            "the loss in 21800th batch is: 0.884857\n",
            "the loss in 22000th batch is: 0.845007\n",
            "the loss in 22200th batch is: 0.858222\n",
            "the loss in 22400th batch is: 0.877010\n",
            "the loss in 22600th batch is: 0.854805\n",
            "the loss in 22800th batch is: 0.769423\n",
            "the loss in 23000th batch is: 0.844657\n",
            "the loss in 23200th batch is: 0.811239\n",
            "the loss in 23400th batch is: 0.728936\n",
            "the loss in 23600th batch is: 0.859049\n",
            "the loss in 23800th batch is: 0.771945\n",
            "the loss in 24000th batch is: 0.883793\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2187.000000\n",
            "clicks hr ndcg @ 3 : 0.123551, 0.095973\n",
            "purchase hr and ndcg @3 : 0.137544, 0.112012\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 2899.400000\n",
            "clicks hr ndcg @ 5 : 0.165215, 0.113078\n",
            "purchase hr and ndcg @5 : 0.166316, 0.123850\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 3648.600000\n",
            "clicks hr ndcg @ 8 : 0.208665, 0.127694\n",
            "purchase hr and ndcg @8 : 0.200702, 0.135354\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.022269, 0.014781\n",
            "#############################################################\n",
            "the loss in 24200th batch is: 0.829080\n",
            "the loss in 24400th batch is: 0.787579\n",
            "the loss in 24600th batch is: 0.850792\n",
            "the loss in 24800th batch is: 0.906140\n",
            "the loss in 25000th batch is: 0.865312\n",
            "the loss in 25200th batch is: 0.729290\n",
            "the loss in 25400th batch is: 0.765047\n",
            "the loss in 25600th batch is: 0.791600\n",
            "the loss in 25800th batch is: 0.772415\n",
            "the loss in 26000th batch is: 0.833657\n",
            "the loss in 26200th batch is: 0.761970\n",
            "the loss in 26400th batch is: 0.812861\n",
            "the loss in 26600th batch is: 0.804572\n",
            "the loss in 26800th batch is: 0.730002\n",
            "the loss in 27000th batch is: 0.726759\n",
            "the loss in 27200th batch is: 0.784553\n",
            "the loss in 27400th batch is: 0.720517\n",
            "the loss in 27600th batch is: 0.700789\n",
            "the loss in 27800th batch is: 0.777649\n",
            "the loss in 28000th batch is: 0.739901\n",
            "the loss in 28200th batch is: 0.693225\n",
            "the loss in 28400th batch is: 0.701739\n",
            "the loss in 28600th batch is: 0.687577\n",
            "the loss in 28800th batch is: 0.643792\n",
            "the loss in 29000th batch is: 0.729790\n",
            "the loss in 29200th batch is: 0.674688\n",
            "the loss in 29400th batch is: 0.730838\n",
            "the loss in 29600th batch is: 0.659525\n",
            "the loss in 29800th batch is: 0.789394\n",
            "the loss in 30000th batch is: 0.819557\n",
            "the loss in 30200th batch is: 0.730896\n",
            "the loss in 30400th batch is: 0.706781\n",
            "the loss in 30600th batch is: 0.710233\n",
            "the loss in 30800th batch is: 0.692946\n",
            "the loss in 31000th batch is: 0.672593\n",
            "the loss in 31200th batch is: 0.690199\n",
            "the loss in 31400th batch is: 0.714321\n",
            "the loss in 31600th batch is: 0.701848\n",
            "the loss in 31800th batch is: 0.735602\n",
            "the loss in 32000th batch is: 0.664425\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2456.200000\n",
            "clicks hr ndcg @ 3 : 0.139263, 0.108543\n",
            "purchase hr and ndcg @3 : 0.148772, 0.120709\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3251.000000\n",
            "clicks hr ndcg @ 5 : 0.184923, 0.127320\n",
            "purchase hr and ndcg @5 : 0.190175, 0.137649\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4010.200000\n",
            "clicks hr ndcg @ 8 : 0.229739, 0.142410\n",
            "purchase hr and ndcg @8 : 0.216140, 0.146514\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.028533, 0.018219\n",
            "#############################################################\n",
            "the loss in 32200th batch is: 0.628893\n",
            "the loss in 32400th batch is: 0.688451\n",
            "the loss in 32600th batch is: 0.742267\n",
            "the loss in 32800th batch is: 0.664296\n",
            "the loss in 33000th batch is: 0.676175\n",
            "the loss in 33200th batch is: 0.609219\n",
            "the loss in 33400th batch is: 0.709069\n",
            "the loss in 33600th batch is: 0.814960\n",
            "the loss in 33800th batch is: 0.679075\n",
            "the loss in 34000th batch is: 0.655249\n",
            "the loss in 34200th batch is: 0.740592\n",
            "the loss in 34400th batch is: 0.675777\n",
            "the loss in 34600th batch is: 0.718251\n",
            "the loss in 34800th batch is: 0.737073\n",
            "the loss in 35000th batch is: 0.706727\n",
            "the loss in 35200th batch is: 0.624894\n",
            "the loss in 35400th batch is: 0.650427\n",
            "the loss in 35600th batch is: 0.693832\n",
            "the loss in 35800th batch is: 0.765647\n",
            "the loss in 36000th batch is: 0.646730\n",
            "the loss in 36200th batch is: 0.631601\n",
            "the loss in 36400th batch is: 0.701920\n",
            "the loss in 36600th batch is: 0.703340\n",
            "the loss in 36800th batch is: 0.647003\n",
            "the loss in 37000th batch is: 0.685563\n",
            "the loss in 37200th batch is: 0.714566\n",
            "the loss in 37400th batch is: 0.653671\n",
            "the loss in 37600th batch is: 0.690313\n",
            "the loss in 37800th batch is: 0.702062\n",
            "the loss in 38000th batch is: 0.672249\n",
            "the loss in 38200th batch is: 0.624028\n",
            "the loss in 38400th batch is: 0.647904\n",
            "the loss in 38600th batch is: 0.728107\n",
            "the loss in 38800th batch is: 0.711551\n",
            "the loss in 39000th batch is: 0.659437\n",
            "the loss in 39200th batch is: 0.653806\n",
            "the loss in 39400th batch is: 0.678067\n",
            "the loss in 39600th batch is: 0.636506\n",
            "the loss in 39800th batch is: 0.694116\n",
            "the loss in 40000th batch is: 0.684912\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2646.800000\n",
            "clicks hr ndcg @ 3 : 0.149788, 0.117146\n",
            "purchase hr and ndcg @3 : 0.163509, 0.134728\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3436.600000\n",
            "clicks hr ndcg @ 5 : 0.195944, 0.136154\n",
            "purchase hr and ndcg @5 : 0.195789, 0.147892\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4225.000000\n",
            "clicks hr ndcg @ 8 : 0.242262, 0.151772\n",
            "purchase hr and ndcg @8 : 0.225263, 0.157861\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.033285, 0.021345\n",
            "#############################################################\n",
            "the loss in 40200th batch is: 0.660157\n",
            "the loss in 40400th batch is: 0.654703\n",
            "the loss in 40600th batch is: 0.631162\n",
            "the loss in 40800th batch is: 0.588362\n",
            "the loss in 41000th batch is: 0.678147\n",
            "the loss in 41200th batch is: 0.592163\n",
            "the loss in 41400th batch is: 0.663782\n",
            "the loss in 41600th batch is: 0.553820\n",
            "the loss in 41800th batch is: 0.663210\n",
            "the loss in 42000th batch is: 0.646154\n",
            "the loss in 42200th batch is: 0.630384\n",
            "the loss in 42400th batch is: 0.594022\n",
            "the loss in 42600th batch is: 0.618717\n",
            "the loss in 42800th batch is: 0.611800\n",
            "the loss in 43000th batch is: 0.650398\n",
            "the loss in 43200th batch is: 0.623603\n",
            "the loss in 43400th batch is: 0.600627\n",
            "the loss in 43600th batch is: 0.622019\n",
            "the loss in 43800th batch is: 0.639733\n",
            "the loss in 44000th batch is: 0.597836\n",
            "the loss in 44200th batch is: 0.593234\n",
            "the loss in 44400th batch is: 0.589902\n",
            "the loss in 44600th batch is: 0.624162\n",
            "the loss in 44800th batch is: 0.609170\n",
            "the loss in 45000th batch is: 0.637166\n",
            "the loss in 45200th batch is: 0.574823\n",
            "the loss in 45400th batch is: 0.554281\n",
            "the loss in 45600th batch is: 0.634769\n",
            "the loss in 45800th batch is: 0.617294\n",
            "the loss in 46000th batch is: 0.618800\n",
            "the loss in 46200th batch is: 0.567187\n",
            "the loss in 46400th batch is: 0.633967\n",
            "the loss in 46600th batch is: 0.652986\n",
            "the loss in 46800th batch is: 0.599946\n",
            "the loss in 47000th batch is: 0.648436\n",
            "the loss in 47200th batch is: 0.597521\n",
            "the loss in 47400th batch is: 0.640738\n",
            "the loss in 47600th batch is: 0.570189\n",
            "the loss in 47800th batch is: 0.639404\n",
            "the loss in 48000th batch is: 0.583691\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2753.800000\n",
            "clicks hr ndcg @ 3 : 0.155807, 0.121466\n",
            "purchase hr and ndcg @3 : 0.170526, 0.139531\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3569.400000\n",
            "clicks hr ndcg @ 5 : 0.203378, 0.140981\n",
            "purchase hr and ndcg @5 : 0.204912, 0.153725\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4378.000000\n",
            "clicks hr ndcg @ 8 : 0.250763, 0.156913\n",
            "purchase hr and ndcg @8 : 0.236491, 0.164467\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.036787, 0.024442\n",
            "#############################################################\n",
            "the loss in 48200th batch is: 0.597880\n",
            "the loss in 48400th batch is: 0.607972\n",
            "the loss in 48600th batch is: 0.639681\n",
            "the loss in 48800th batch is: 0.642549\n",
            "the loss in 49000th batch is: 0.675302\n",
            "the loss in 49200th batch is: 0.586334\n",
            "the loss in 49400th batch is: 0.589372\n",
            "the loss in 49600th batch is: 0.630349\n",
            "the loss in 49800th batch is: 0.588768\n",
            "the loss in 50000th batch is: 0.636427\n",
            "the loss in 50200th batch is: 0.601903\n",
            "the loss in 50400th batch is: 0.719306\n",
            "the loss in 50600th batch is: 0.584057\n",
            "the loss in 50800th batch is: 0.592938\n",
            "the loss in 51000th batch is: 0.666164\n",
            "the loss in 51200th batch is: 0.663749\n",
            "the loss in 51400th batch is: 0.562674\n",
            "the loss in 51600th batch is: 0.584117\n",
            "the loss in 51800th batch is: 0.655329\n",
            "the loss in 52000th batch is: 0.607886\n",
            "the loss in 52200th batch is: 0.565402\n",
            "the loss in 52400th batch is: 0.653935\n",
            "the loss in 52600th batch is: 0.590520\n",
            "the loss in 52800th batch is: 0.568383\n",
            "the loss in 53000th batch is: 0.643408\n",
            "the loss in 53200th batch is: 0.603898\n",
            "the loss in 53400th batch is: 0.561229\n",
            "the loss in 53600th batch is: 0.514602\n",
            "the loss in 53800th batch is: 0.532403\n",
            "the loss in 54000th batch is: 0.514682\n",
            "the loss in 54200th batch is: 0.640331\n",
            "the loss in 54400th batch is: 0.587542\n",
            "the loss in 54600th batch is: 0.583761\n",
            "the loss in 54800th batch is: 0.525573\n",
            "the loss in 55000th batch is: 0.561577\n",
            "the loss in 55200th batch is: 0.610604\n",
            "the loss in 55400th batch is: 0.638504\n",
            "the loss in 55600th batch is: 0.609206\n",
            "the loss in 55800th batch is: 0.659310\n",
            "the loss in 56000th batch is: 0.603891\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2839.000000\n",
            "clicks hr ndcg @ 3 : 0.160163, 0.124946\n",
            "purchase hr and ndcg @3 : 0.181053, 0.145304\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3672.800000\n",
            "clicks hr ndcg @ 5 : 0.209360, 0.145148\n",
            "purchase hr and ndcg @5 : 0.209825, 0.157142\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4501.000000\n",
            "clicks hr ndcg @ 8 : 0.257403, 0.161326\n",
            "purchase hr and ndcg @8 : 0.247719, 0.169836\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.040112, 0.026054\n",
            "#############################################################\n",
            "the loss in 56200th batch is: 0.579923\n",
            "the loss in 56400th batch is: 0.597613\n",
            "the loss in 56600th batch is: 0.626995\n",
            "the loss in 56800th batch is: 0.575845\n",
            "the loss in 57000th batch is: 0.536772\n",
            "the loss in 57200th batch is: 0.568602\n",
            "the loss in 57400th batch is: 0.588327\n",
            "the loss in 57600th batch is: 0.539907\n",
            "the loss in 57800th batch is: 0.557040\n",
            "the loss in 58000th batch is: 0.610467\n",
            "the loss in 58200th batch is: 0.561222\n",
            "the loss in 58400th batch is: 0.550515\n",
            "the loss in 58600th batch is: 0.587909\n",
            "the loss in 58800th batch is: 0.590970\n",
            "the loss in 59000th batch is: 0.586756\n",
            "the loss in 59200th batch is: 0.664764\n",
            "the loss in 59400th batch is: 0.581945\n",
            "the loss in 59600th batch is: 0.518048\n",
            "the loss in 59800th batch is: 0.651937\n",
            "the loss in 60000th batch is: 0.668260\n",
            "the loss in 60200th batch is: 0.600354\n",
            "the loss in 60400th batch is: 0.567001\n",
            "the loss in 60600th batch is: 0.557247\n",
            "the loss in 60800th batch is: 0.602335\n",
            "the loss in 61000th batch is: 0.612643\n",
            "the loss in 61200th batch is: 0.579407\n",
            "the loss in 61400th batch is: 0.570945\n",
            "the loss in 61600th batch is: 0.561944\n",
            "the loss in 61800th batch is: 0.577527\n",
            "the loss in 62000th batch is: 0.670724\n",
            "the loss in 62200th batch is: 0.599661\n",
            "the loss in 62400th batch is: 0.626679\n",
            "the loss in 62600th batch is: 0.544663\n",
            "the loss in 62800th batch is: 0.618128\n",
            "the loss in 63000th batch is: 0.587460\n",
            "the loss in 63200th batch is: 0.563281\n",
            "the loss in 63400th batch is: 0.558972\n",
            "the loss in 63600th batch is: 0.585491\n",
            "the loss in 63800th batch is: 0.528535\n",
            "the loss in 64000th batch is: 0.568219\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2897.200000\n",
            "clicks hr ndcg @ 3 : 0.164458, 0.128519\n",
            "purchase hr and ndcg @3 : 0.173333, 0.142981\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3738.000000\n",
            "clicks hr ndcg @ 5 : 0.213158, 0.148529\n",
            "purchase hr and ndcg @5 : 0.212632, 0.158891\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4567.000000\n",
            "clicks hr ndcg @ 8 : 0.261126, 0.164699\n",
            "purchase hr and ndcg @8 : 0.251930, 0.172076\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.042577, 0.026694\n",
            "#############################################################\n",
            "the loss in 64200th batch is: 0.585238\n",
            "the loss in 64400th batch is: 0.547424\n",
            "the loss in 64600th batch is: 0.465466\n",
            "the loss in 64800th batch is: 0.661211\n",
            "the loss in 65000th batch is: 0.552478\n",
            "the loss in 65200th batch is: 0.602827\n",
            "the loss in 65400th batch is: 0.612702\n",
            "the loss in 65600th batch is: 0.527716\n",
            "the loss in 65800th batch is: 0.523825\n",
            "the loss in 66000th batch is: 0.552417\n",
            "the loss in 66200th batch is: 0.523371\n",
            "the loss in 66400th batch is: 0.547269\n",
            "the loss in 66600th batch is: 0.480639\n",
            "the loss in 66800th batch is: 0.661488\n",
            "the loss in 67000th batch is: 0.583926\n",
            "the loss in 67200th batch is: 0.575115\n",
            "the loss in 67400th batch is: 0.512582\n",
            "the loss in 67600th batch is: 0.555854\n",
            "the loss in 67800th batch is: 0.609352\n",
            "the loss in 68000th batch is: 0.586843\n",
            "the loss in 68200th batch is: 0.524895\n",
            "the loss in 68400th batch is: 0.604606\n",
            "the loss in 68600th batch is: 0.576486\n",
            "the loss in 68800th batch is: 0.566525\n",
            "the loss in 69000th batch is: 0.600999\n",
            "the loss in 69200th batch is: 0.576615\n",
            "the loss in 69400th batch is: 0.535300\n",
            "the loss in 69600th batch is: 0.583492\n",
            "the loss in 69800th batch is: 0.545618\n",
            "the loss in 70000th batch is: 0.521387\n",
            "the loss in 70200th batch is: 0.575741\n",
            "the loss in 70400th batch is: 0.550833\n",
            "the loss in 70600th batch is: 0.501018\n",
            "the loss in 70800th batch is: 0.606439\n",
            "the loss in 71000th batch is: 0.589159\n",
            "the loss in 71200th batch is: 0.506656\n",
            "the loss in 71400th batch is: 0.522877\n",
            "the loss in 71600th batch is: 0.557123\n",
            "the loss in 71800th batch is: 0.584474\n",
            "the loss in 72000th batch is: 0.604382\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2944.800000\n",
            "clicks hr ndcg @ 3 : 0.167039, 0.130640\n",
            "purchase hr and ndcg @3 : 0.177544, 0.145270\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3791.600000\n",
            "clicks hr ndcg @ 5 : 0.216422, 0.150939\n",
            "purchase hr and ndcg @5 : 0.213333, 0.159823\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4604.200000\n",
            "clicks hr ndcg @ 8 : 0.263993, 0.166978\n",
            "purchase hr and ndcg @8 : 0.245614, 0.170684\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.045167, 0.027002\n",
            "#############################################################\n",
            "the loss in 72200th batch is: 0.578278\n",
            "the loss in 72400th batch is: 0.554448\n",
            "the loss in 72600th batch is: 0.534329\n",
            "the loss in 72800th batch is: 0.538689\n",
            "the loss in 73000th batch is: 0.586717\n",
            "the loss in 73200th batch is: 0.528527\n",
            "the loss in 73400th batch is: 0.568737\n",
            "the loss in 73600th batch is: 0.537777\n",
            "the loss in 73800th batch is: 0.625338\n",
            "the loss in 74000th batch is: 0.469912\n",
            "the loss in 74200th batch is: 0.564339\n",
            "the loss in 74400th batch is: 0.453236\n",
            "the loss in 74600th batch is: 0.594558\n",
            "the loss in 74800th batch is: 0.525640\n",
            "the loss in 75000th batch is: 0.575403\n",
            "the loss in 75200th batch is: 0.556145\n",
            "the loss in 75400th batch is: 0.559927\n",
            "the loss in 75600th batch is: 0.503975\n",
            "the loss in 75800th batch is: 0.587035\n",
            "the loss in 76000th batch is: 0.481885\n",
            "the loss in 76200th batch is: 0.529213\n",
            "the loss in 76400th batch is: 0.595220\n",
            "the loss in 76600th batch is: 0.458643\n",
            "the loss in 76800th batch is: 0.464586\n",
            "the loss in 77000th batch is: 0.575031\n",
            "the loss in 77200th batch is: 0.512222\n",
            "the loss in 77400th batch is: 0.502512\n",
            "the loss in 77600th batch is: 0.545599\n",
            "the loss in 77800th batch is: 0.499600\n",
            "the loss in 78000th batch is: 0.572016\n",
            "the loss in 78200th batch is: 0.556781\n",
            "the loss in 78400th batch is: 0.503325\n",
            "the loss in 78600th batch is: 0.509471\n",
            "the loss in 78800th batch is: 0.501913\n",
            "the loss in 79000th batch is: 0.488001\n",
            "the loss in 79200th batch is: 0.575261\n",
            "the loss in 79400th batch is: 0.487421\n",
            "the loss in 79600th batch is: 0.518760\n",
            "the loss in 79800th batch is: 0.512804\n",
            "the loss in 80000th batch is: 0.495663\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2975.600000\n",
            "clicks hr ndcg @ 3 : 0.168950, 0.131853\n",
            "purchase hr and ndcg @3 : 0.177544, 0.143274\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3814.000000\n",
            "clicks hr ndcg @ 5 : 0.217440, 0.151792\n",
            "purchase hr and ndcg @5 : 0.217544, 0.159793\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4630.400000\n",
            "clicks hr ndcg @ 8 : 0.264999, 0.167819\n",
            "purchase hr and ndcg @8 : 0.252632, 0.171599\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.046876, 0.027599\n",
            "#############################################################\n",
            "the loss in 80200th batch is: 0.534582\n",
            "the loss in 80400th batch is: 0.524397\n",
            "the loss in 80600th batch is: 0.450745\n",
            "the loss in 80800th batch is: 0.469166\n",
            "the loss in 81000th batch is: 0.519598\n",
            "the loss in 81200th batch is: 0.486613\n",
            "the loss in 81400th batch is: 0.554600\n",
            "the loss in 81600th batch is: 0.510156\n",
            "the loss in 81800th batch is: 0.519029\n",
            "the loss in 82000th batch is: 0.557168\n",
            "the loss in 82200th batch is: 0.485702\n",
            "the loss in 82400th batch is: 0.577180\n",
            "the loss in 82600th batch is: 0.500100\n",
            "the loss in 82800th batch is: 0.472437\n",
            "the loss in 83000th batch is: 0.520062\n",
            "the loss in 83200th batch is: 0.555894\n",
            "the loss in 83400th batch is: 0.514118\n",
            "the loss in 83600th batch is: 0.578093\n",
            "the loss in 83800th batch is: 0.570816\n",
            "the loss in 84000th batch is: 0.481641\n",
            "the loss in 84200th batch is: 0.553180\n",
            "the loss in 84400th batch is: 0.539238\n",
            "the loss in 84600th batch is: 0.577950\n",
            "the loss in 84800th batch is: 0.571330\n",
            "the loss in 85000th batch is: 0.513264\n",
            "the loss in 85200th batch is: 0.507701\n",
            "the loss in 85400th batch is: 0.509527\n",
            "the loss in 85600th batch is: 0.461925\n",
            "the loss in 85800th batch is: 0.492561\n",
            "the loss in 86000th batch is: 0.604855\n",
            "the loss in 86200th batch is: 0.565277\n",
            "the loss in 86400th batch is: 0.549727\n",
            "the loss in 86600th batch is: 0.532644\n",
            "the loss in 86800th batch is: 0.534381\n",
            "the loss in 87000th batch is: 0.471606\n",
            "the loss in 87200th batch is: 0.524632\n",
            "the loss in 87400th batch is: 0.567596\n",
            "the loss in 87600th batch is: 0.489580\n",
            "the loss in 87800th batch is: 0.512690\n",
            "the loss in 88000th batch is: 0.497189\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 2991.000000\n",
            "clicks hr ndcg @ 3 : 0.170216, 0.132713\n",
            "purchase hr and ndcg @3 : 0.174035, 0.140391\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3851.800000\n",
            "clicks hr ndcg @ 5 : 0.220034, 0.153202\n",
            "purchase hr and ndcg @5 : 0.214737, 0.156998\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4681.200000\n",
            "clicks hr ndcg @ 8 : 0.267841, 0.169320\n",
            "purchase hr and ndcg @8 : 0.256140, 0.171182\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.048266, 0.028349\n",
            "#############################################################\n",
            "the loss in 88200th batch is: 0.490675\n",
            "the loss in 88400th batch is: 0.534678\n",
            "the loss in 88600th batch is: 0.561750\n",
            "the loss in 88800th batch is: 0.497861\n",
            "the loss in 89000th batch is: 0.508711\n",
            "the loss in 89200th batch is: 0.553656\n",
            "the loss in 89400th batch is: 0.519848\n",
            "the loss in 89600th batch is: 0.537463\n",
            "the loss in 89800th batch is: 0.490349\n",
            "the loss in 90000th batch is: 0.513973\n",
            "the loss in 90200th batch is: 0.560121\n",
            "the loss in 90400th batch is: 0.541606\n",
            "the loss in 90600th batch is: 0.521291\n",
            "the loss in 90800th batch is: 0.522100\n",
            "the loss in 91000th batch is: 0.514965\n",
            "the loss in 91200th batch is: 0.497901\n",
            "the loss in 91400th batch is: 0.504441\n",
            "the loss in 91600th batch is: 0.544602\n",
            "the loss in 91800th batch is: 0.537583\n",
            "the loss in 92000th batch is: 0.590464\n",
            "the loss in 92200th batch is: 0.484826\n",
            "the loss in 92400th batch is: 0.553719\n",
            "the loss in 92600th batch is: 0.477962\n",
            "the loss in 92800th batch is: 0.492817\n",
            "the loss in 93000th batch is: 0.589310\n",
            "the loss in 93200th batch is: 0.496333\n",
            "the loss in 93400th batch is: 0.519038\n",
            "the loss in 93600th batch is: 0.549441\n",
            "the loss in 93800th batch is: 0.558588\n",
            "the loss in 94000th batch is: 0.514735\n",
            "the loss in 94200th batch is: 0.528055\n",
            "the loss in 94400th batch is: 0.488002\n",
            "the loss in 94600th batch is: 0.510086\n",
            "the loss in 94800th batch is: 0.465851\n",
            "the loss in 95000th batch is: 0.534886\n",
            "the loss in 95200th batch is: 0.487051\n",
            "the loss in 95400th batch is: 0.503708\n",
            "the loss in 95600th batch is: 0.519686\n",
            "the loss in 95800th batch is: 0.536262\n",
            "the loss in 96000th batch is: 0.545034\n",
            "#############################################################\n",
            "total clicks: 80574, total purchase:1425\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 3: 3005.400000\n",
            "clicks hr ndcg @ 3 : 0.170241, 0.132928\n",
            "purchase hr and ndcg @3 : 0.183860, 0.147701\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 5: 3883.000000\n",
            "clicks hr ndcg @ 5 : 0.221722, 0.154133\n",
            "purchase hr and ndcg @5 : 0.217544, 0.161593\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "cumulative reward @ 8: 4686.600000\n",
            "clicks hr ndcg @ 8 : 0.268486, 0.169888\n",
            "purchase hr and ndcg @8 : 0.252632, 0.173545\n",
            "off-line corrected evaluation (click_ng,purchase_ng)@10: 0.049511, 0.029277\n",
            "#############################################################\n",
            "Traceback (most recent call last):\n",
            "  File \"DRL1/src/SA2C.py\", line 426, in <module>\n",
            "    target_Qs_selector = sess.run(mainQN.output1,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 967, in run\n",
            "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
            "    results = self._do_run(handle, final_targets, final_fetches,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1370, in _do_run\n",
            "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1377, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1360, in _run_fn\n",
            "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/client/session.py\", line 1453, in _call_tf_sessionrun\n",
            "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! python DRL1/src/SA2C.py  --model=SASRec"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClYfZr0R9iMS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}